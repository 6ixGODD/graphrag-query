# Copyright (c) 2024 Microsoft Corporation.
# Licensed under the MIT License.

from __future__ import annotations

import typing

import pydantic

from . import _search


class Delta(pydantic.BaseModel):
    content: typing.Optional[str] = None
    """The contents of the message."""

    refusal: typing.Optional[str] = None
    """The refusal message generated by the model."""


class ChunkChoice(pydantic.BaseModel):
    finish_reason: typing.Optional[str] = None
    """
    The reason the model stopped generating tokens.

    This will be `stop` if the model hit a natural stop point or a provided stop
    sequence, `length` if the maximum number of tokens specified in the request 
    was reached, `content_filter` if content was omitted due to a flag from our 
    content filters, `tool_calls` if the model called a tool, or `function_call`
    (deprecated) if the model called a function.
    """

    delta: Delta
    """A chat completion delta generated by streamed model responses."""


class SearchResultChunk(pydantic.BaseModel):
    created: int
    """Unix timestamp of the result creation time."""

    model: str
    """The model used for the chat completion."""

    system_fingerprint: typing.Optional[str] = None
    """
    This fingerprint represents the backend configuration that the model runs 
    with.
    """

    choice: ChunkChoice
    """A list of chat completion choices."""

    usage: typing.Optional[_search.Usage] = None
    """Usage statistics for the completion request."""
