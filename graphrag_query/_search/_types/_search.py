# Copyright (c) 2024 Microsoft Corporation.
# Licensed under the MIT License.

from __future__ import annotations

import typing

import pydantic


class Usage(pydantic.BaseModel):
    completion_tokens: int
    """Number of tokens in the generated completion."""

    prompt_tokens: int
    """Number of tokens in the prompt."""

    total_tokens: int
    """Total number of tokens used in the request (prompt + completion)."""


class Message(pydantic.BaseModel):
    content: typing.Union[str, typing.Dict[str, typing.Any], typing.List[typing.Dict[str, typing.Any]], None] = None
    """The contents of the message."""

    refusal: typing.Optional[str] = None
    """The refusal message generated by the model."""


class Choice(pydantic.BaseModel):
    finish_reason: typing.Optional[str]
    """
    The reason the model stopped generating tokens.

    This will be `stop` if the model hit a natural stop point or a provided stop
    sequence, `length` if the maximum number of tokens specified in the request 
    was reached, `content_filter` if content was omitted due to a flag from our 
    content filters, `tool_calls` if the model called a tool, or `function_call`
    (deprecated) if the model called a function.
    """

    message: Message
    """A chat completion message generated by the model."""


class SearchResult(pydantic.BaseModel):
    created: int
    """Unix timestamp of the result creation time."""

    model: str
    """The model used for the chat completion."""

    system_fingerprint: typing.Optional[str] = None
    """
    This fingerprint represents the backend configuration that the model runs 
    with.
    """

    choice: Choice
    """A list of chat completion choices."""

    usage: typing.Optional[Usage] = None
    """Usage statistics for the completion request."""
